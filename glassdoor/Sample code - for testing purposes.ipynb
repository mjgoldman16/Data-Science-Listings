{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "pd.set_option('display.max_columns',500)\n",
    "pd.set_option('display.max_rows',500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./Data/testing_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company_cons     312\n",
      "company_info     311\n",
      "company_name       0\n",
      "company_pros     311\n",
      "description        4\n",
      "job_location     311\n",
      "job_title          0\n",
      "outlook          311\n",
      "post_date          0\n",
      "rating             0\n",
      "recommend        311\n",
      "salary_est      4020\n",
      "salary_high     4020\n",
      "salary_low      4020\n",
      "dtype: int64\n",
      "265\n",
      "2646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['company_cons', 'company_info', 'company_name', 'company_pros',\n",
       "       'description', 'job_location', 'job_title', 'outlook', 'post_date',\n",
       "       'rating', 'recommend', 'salary_est', 'salary_high', 'salary_low'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.isnull().sum())\n",
    "print(len(pd.unique(df[\"job_location\"])))\n",
    "print(len(pd.unique(df[\"company_name\"]))) #2.6 for the larger df\n",
    "# print(len(pd.unique(df[\"Industry\"])))\n",
    "# print(len(pd.unique(df[\"Type\"])))\n",
    "# print(len(pd.unique(df[\"Size\"])))\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>company_cons</th>\n",
       "      <th>company_info</th>\n",
       "      <th>company_name</th>\n",
       "      <th>company_pros</th>\n",
       "      <th>description</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_title</th>\n",
       "      <th>outlook</th>\n",
       "      <th>post_date</th>\n",
       "      <th>rating</th>\n",
       "      <th>recommend</th>\n",
       "      <th>salary_est</th>\n",
       "      <th>salary_high</th>\n",
       "      <th>salary_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12486</th>\n",
       "      <td>12796</td>\n",
       "      <td>Disconnect between HQ and US</td>\n",
       "      <td>[('Headquarters', 'Paris, France'), ('Size', '...</td>\n",
       "      <td>UPS Professional</td>\n",
       "      <td>High quality product\\nHigh level education\\nSm...</td>\n",
       "      <td>This is an exciting opportunity to join a gro...</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Digital Marketing Data Manager</td>\n",
       "      <td>Positive Outlook</td>\n",
       "      <td>30+ days ago</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Recommends</td>\n",
       "      <td>$87,000</td>\n",
       "      <td>$107k</td>\n",
       "      <td>$73k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12487</th>\n",
       "      <td>12797</td>\n",
       "      <td>Non paid travel time\\nNot many hours\\nSlow pap...</td>\n",
       "      <td>[('Headquarters', 'Paris, France'), ('Size', '...</td>\n",
       "      <td>UPS Professional</td>\n",
       "      <td>Lenient dress code\\nGratis\\nFun work environme...</td>\n",
       "      <td>This is an exciting opportunity to join a gro...</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Digital Marketing Data Manager</td>\n",
       "      <td>Negative Outlook</td>\n",
       "      <td>30+ days ago</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Doesn't Recommend</td>\n",
       "      <td>$87,000</td>\n",
       "      <td>$107k</td>\n",
       "      <td>$73k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12488</th>\n",
       "      <td>12798</td>\n",
       "      <td>Could be made a full-time position</td>\n",
       "      <td>[('Headquarters', 'Paris, France'), ('Size', '...</td>\n",
       "      <td>UPS Professional</td>\n",
       "      <td>A lot of attention and support in your work in...</td>\n",
       "      <td>This is an exciting opportunity to join a gro...</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Digital Marketing Data Manager</td>\n",
       "      <td>Positive Outlook</td>\n",
       "      <td>30+ days ago</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Recommends</td>\n",
       "      <td>$87,000</td>\n",
       "      <td>$107k</td>\n",
       "      <td>$73k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12489</th>\n",
       "      <td>12799</td>\n",
       "      <td>Do not treat interns nicely</td>\n",
       "      <td>[('Headquarters', 'Paris, France'), ('Size', '...</td>\n",
       "      <td>UPS Professional</td>\n",
       "      <td>Pretty good pay, laid back dress code</td>\n",
       "      <td>This is an exciting opportunity to join a gro...</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Digital Marketing Data Manager</td>\n",
       "      <td>Recommendation or Outlook not listed</td>\n",
       "      <td>30+ days ago</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Recommendation or Outlook not listed</td>\n",
       "      <td>$87,000</td>\n",
       "      <td>$107k</td>\n",
       "      <td>$73k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12490</th>\n",
       "      <td>12800</td>\n",
       "      <td>98% females work there, very clicky, wasn't gi...</td>\n",
       "      <td>[('Headquarters', 'Paris, France'), ('Size', '...</td>\n",
       "      <td>UPS Professional</td>\n",
       "      <td>easy work, beautiful office, if you're a full ...</td>\n",
       "      <td>This is an exciting opportunity to join a gro...</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Digital Marketing Data Manager</td>\n",
       "      <td>Neutral Outlook</td>\n",
       "      <td>30+ days ago</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Recommends</td>\n",
       "      <td>$87,000</td>\n",
       "      <td>$107k</td>\n",
       "      <td>$73k</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                                       company_cons  \\\n",
       "12486  12796                       Disconnect between HQ and US   \n",
       "12487  12797  Non paid travel time\\nNot many hours\\nSlow pap...   \n",
       "12488  12798                 Could be made a full-time position   \n",
       "12489  12799                        Do not treat interns nicely   \n",
       "12490  12800  98% females work there, very clicky, wasn't gi...   \n",
       "\n",
       "                                            company_info      company_name  \\\n",
       "12486  [('Headquarters', 'Paris, France'), ('Size', '...  UPS Professional   \n",
       "12487  [('Headquarters', 'Paris, France'), ('Size', '...  UPS Professional   \n",
       "12488  [('Headquarters', 'Paris, France'), ('Size', '...  UPS Professional   \n",
       "12489  [('Headquarters', 'Paris, France'), ('Size', '...  UPS Professional   \n",
       "12490  [('Headquarters', 'Paris, France'), ('Size', '...  UPS Professional   \n",
       "\n",
       "                                            company_pros  \\\n",
       "12486  High quality product\\nHigh level education\\nSm...   \n",
       "12487  Lenient dress code\\nGratis\\nFun work environme...   \n",
       "12488  A lot of attention and support in your work in...   \n",
       "12489              Pretty good pay, laid back dress code   \n",
       "12490  easy work, beautiful office, if you're a full ...   \n",
       "\n",
       "                                             description job_location  \\\n",
       "12486   This is an exciting opportunity to join a gro...  Atlanta, GA   \n",
       "12487   This is an exciting opportunity to join a gro...  Atlanta, GA   \n",
       "12488   This is an exciting opportunity to join a gro...  Atlanta, GA   \n",
       "12489   This is an exciting opportunity to join a gro...  Atlanta, GA   \n",
       "12490   This is an exciting opportunity to join a gro...  Atlanta, GA   \n",
       "\n",
       "                            job_title                               outlook  \\\n",
       "12486  Digital Marketing Data Manager                      Positive Outlook   \n",
       "12487  Digital Marketing Data Manager                      Negative Outlook   \n",
       "12488  Digital Marketing Data Manager                      Positive Outlook   \n",
       "12489  Digital Marketing Data Manager  Recommendation or Outlook not listed   \n",
       "12490  Digital Marketing Data Manager                       Neutral Outlook   \n",
       "\n",
       "          post_date rating                             recommend salary_est  \\\n",
       "12486  30+ days ago    3.1                            Recommends    $87,000   \n",
       "12487  30+ days ago    3.1                     Doesn't Recommend    $87,000   \n",
       "12488  30+ days ago    3.1                            Recommends    $87,000   \n",
       "12489  30+ days ago    3.1  Recommendation or Outlook not listed    $87,000   \n",
       "12490  30+ days ago    3.1                            Recommends    $87,000   \n",
       "\n",
       "      salary_high salary_low  \n",
       "12486       $107k       $73k  \n",
       "12487       $107k       $73k  \n",
       "12488       $107k       $73k  \n",
       "12489       $107k       $73k  \n",
       "12490       $107k       $73k  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[(df[\"company_name\"]!=\"*** ERROR - NO COMPANY LISTED. SEE DESCRIPTION FOR POSSIBLE HINTS *** [XX]\") & (df[\"company_info\"].isnull()!=True)]\n",
    "print((df[\"company_name\"]==\"*** ERROR - NO COMPANY LISTED. SEE DESCRIPTION FOR POSSIBLE HINTS *** [XX]\").sum())\n",
    "# print(df[\"company_info\"].isnull().sum())\n",
    "# # print(df[\"company)info\"].contains(\">\").sum())\n",
    "# print(len(df))\n",
    "# df.dropna()\n",
    "# print(len(df))\n",
    "df = df.reset_index()\n",
    "df[df[\"company_name\"]==\"UPS Professional\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "df[\"company_info\"] = df[\"company_info\"].apply(literal_eval)# df[\"company_info\"]\n",
    "\n",
    "df[\"company_info\"] = pd.Series([dict(i) for i in df[\"company_info\"]])\n",
    "# df[\"company_info\"]\n",
    "# df[\"company_info\"].items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df.drop('company_info', axis = 1), df[\"company_info\"].apply(pd.Series)], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sizes = ['1 to 50 employees', '51 to 200 employees',  '201 to 500 employees', '501 to 1000 employees',\n",
    "         '1001 to 5000 employees', '5001 to 10000 employees', '10000+ employees', 'Unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>company_cons</th>\n",
       "      <th>company_name</th>\n",
       "      <th>company_pros</th>\n",
       "      <th>description</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_title</th>\n",
       "      <th>outlook</th>\n",
       "      <th>post_date</th>\n",
       "      <th>rating</th>\n",
       "      <th>recommend</th>\n",
       "      <th>salary_est</th>\n",
       "      <th>salary_high</th>\n",
       "      <th>salary_low</th>\n",
       "      <th>Competitors</th>\n",
       "      <th>Founded</th>\n",
       "      <th>Headquarters</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Now known as</th>\n",
       "      <th>Part of</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Size</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index, company_cons, company_name, company_pros, description, job_location, job_title, outlook, post_date, rating, recommend, salary_est, salary_high, salary_low, Competitors, Founded, Headquarters, Industry, Now known as , Part of , Revenue, Size, Type]\n",
       "Index: []"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.salary_est==\"$290,000\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./Scraped-data/reviews.csv\")\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# print(100*df[\"salary_est\"].isnull().sum()/len(df[\"salary_est\"]),\"%\")\n",
    "\n",
    "df = df[(df[\"company_name\"]!=\"*** ERROR - NO COMPANY LISTED. SEE DESCRIPTION FOR POSSIBLE HINTS *** [XX]\") & (df[\"company_info\"].isnull()!=True)]\n",
    "print((df[\"company_name\"]==\"*** ERROR - NO COMPANY LISTED. SEE DESCRIPTION FOR POSSIBLE HINTS *** [XX]\").sum())\n",
    "print(df[\"company_info\"].isnull().sum())\n",
    "# print(df[\"company)info\"].contains(\">\").sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[\"company_info\"] = df[\"company_info\"].apply(eval)\n",
    "# df[\"company_info\"]\n",
    "\n",
    "df[\"company_info\"] = pd.Series([dict(i) for i in df[\"company_info\"]])\n",
    "# df[\"company_info\"]\n",
    "# df[\"company_info\"].items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df.drop('company_info', axis = 1), df[\"company_info\"].apply(pd.Series)], axis = 1)\n",
    "#C:\\Users\\mjgol\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\api.py:77: RuntimeWarning: '<' \n",
    "# not supported between instances of 'int' and 'str', sort order is undefined for incomparable objects\n",
    "#   result = result.union(other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216\n",
      "1709\n",
      "38\n",
      "463\n",
      "8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['company_cons', 'company_name', 'company_pros', 'description',\n",
       "       'job_location', 'job_title', 'outlook', 'post_date', 'rating',\n",
       "       'recommend', 'salary_est', 'salary_high', 'salary_low', 'Competitors',\n",
       "       'Founded', 'Headquarters', 'Industry', 'Now known as ', 'Part of ',\n",
       "       'Revenue', 'Size', 'Type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()\n",
    "print(len(pd.unique(df[\"job_location\"])))\n",
    "print(len(pd.unique(df[\"company_name\"]))) #well that isn't a lot \n",
    "print(len(pd.unique(df[\"Industry\"])))\n",
    "print(len(pd.unique(df[\"Type\"])))\n",
    "print(len(pd.unique(df[\"Size\"])))\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in np.where(df[\"Part of \"]==\"\"):\n",
    "    df.loc[i, \"Founded\"] = df.loc[i,\"Type\"]\n",
    "    df.loc[i,\"Type\"] = df.loc[i,\"Industry\"]\n",
    "    df.loc[i,\"Industry\"] = df.loc[i,\"Revenue\"]\n",
    "    df.loc[i,\"Revenue\"] = df.loc[i,\"Competitors\"]\n",
    "    df.loc[i, \"Part of \"] = np.nan\n",
    "    df.loc[i,\"Competitors\"] = np.nan\n",
    "#     type to founded\n",
    "#     revenue to industry\n",
    "#     industry to type\n",
    "#     competitors to revenue\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "company_cons        1\n",
       "company_name        0\n",
       "company_pros        0\n",
       "description         0\n",
       "job_location        0\n",
       "job_title           0\n",
       "outlook             0\n",
       "post_date           0\n",
       "rating              0\n",
       "recommend           0\n",
       "salary_est          0\n",
       "salary_high         0\n",
       "salary_low          0\n",
       "Competitors      2127\n",
       "Founded           100\n",
       "Headquarters       10\n",
       "Industry           60\n",
       "Now known as     8473\n",
       "Part of          8503\n",
       "Revenue           125\n",
       "Size                0\n",
       "Type                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df.drop([\"Now known as \", \"Part of \", \"post_date\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# distinct_df = distinct\n",
    "#Greentech media data analyst - \tBrooklyn, 061 for HQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8503"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[\"Type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "distinct_df = df.drop_duplicates([\"company_name\", \"description\", \"job_location\", \"job_title\"])\n",
    "distinct_df = distinct_df.drop([\"company_cons\", \"company_pros\", \"outlook\", \"recommend\", \"Headquarters\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1664"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_df[\"description\"][5]\n",
    "print(len(distinct_df[\"job_title\"]))\n",
    "# df[df.C.str.contains(\"XYZ\") == False]\n",
    "distinct_df = distinct_df[distinct_df[\"job_title\"].str.contains(\"[Ii]ntern(?!a)\")==False] \n",
    "len(distinct_df)\n",
    "#to prevent internal, or international, etc.\n",
    "#we also don't want internships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "837\n",
      "35\n",
      "693\n",
      "565\n"
     ]
    }
   ],
   "source": [
    "desc_col = distinct_df[\"description\"]\n",
    "desc_col = desc_col.reset_index(drop=True)\n",
    "desc_col.values\n",
    "# [re.search(\"(.{9})years?\",i) for i in test.values]\n",
    "# [re.findall(\"(.{20}) (YEARS?) (.{20})\",i,re.IGNORECASE) for i in test.values]\n",
    "# [re.findall(\"(.{20})(B\\.?A\\.?(?!\\w)|B\\.?S\\.?+)(.{20})\",i, re.IGNORECASE) for i in test.values]\n",
    "\n",
    "##WILL NEED SANITY CHECK ON THIS\n",
    "##EDUCATION LISTINGS\n",
    "bachelors = [re.findall(\"(?<![A-Z])B\\.?S\\.?c?(?![A-Z])|(?<![A-Z])B\\.?A\\.?(?![A-Z])|BACHELOR|UNDERGRAD.{0,40} DEGREE|ASSOCIATE'?S?.{20}DEGREE\",i, re.IGNORECASE) for i in desc_col.values]\n",
    "print(len([x for x in bachelors if x]))\n",
    "masters = [re.findall(\"(MASTER'?S?.{0,40}DEGREE|GRADUATE.{0,40}DEGREE|(?<![A-Z])M\\.?S\\.?(?![A-Z]|\\sDYNAMICS|,\\sDSC)(?!-?~?\\s?OFFICE|\\sEXCEL|\\sWORD|\\sACCESS|-?\\s?SQL)|ADVANCED?.{0,40}DEGREE)\",i,re.IGNORECASE) for i in desc_col.values]\n",
    "mba = [re.findall(\"([\\s|-|/]MBA[\\s|-|/]|[\\s|-|/]MBUS[\\s|-|/]|[\\s|-|/]MBS[\\s|-|/]|MASTERS? OF BUSINESS)\",i,re.IGNORECASE) for i in desc_col.values]\n",
    "print(len([x for x in mba if x]))\n",
    "print(len([x for x in masters if x]))\n",
    "phd = [re.findall(\"(PH\\.?D|ADVANCED?.{0,40}DEGREE|DOCTORA[TE|L]|POST-?\\s?GRADUATE)\",i,re.IGNORECASE) for i in desc_col.values]\n",
    "print(len([x for x in phd if x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "webscrape 9\n"
     ]
    }
   ],
   "source": [
    "# print(\"Frequency of skills listed for Data Science jobs (1.7k unique postings):\")\n",
    "# python = [re.findall(\"PYTHON\",i,re.IGNORECASE) for i in desc_col.values]\n",
    "# print(\"python\",len([x for x in python if x]))\n",
    "# R = [re.findall(\"[\\s,\\.\\-(\\[\\\\\\]R[\\s,\\.\\-)\\]\\\\\\]\",i,re.IGNORECASE) for i in desc_col.values]\n",
    "# print(\"R\", len([x for x in R if x]))\n",
    "# SQL = [re.findall(\"SQL\",i,re.IGNORECASE) for i in desc_col.values]\n",
    "# print(\"SQL\", len([x for x in SQL if x]))\n",
    "# java = [re.findall(\"JAVA(?!SCRIPT)\",i,re.IGNORECASE) for i in desc_col.values]\n",
    "# print(\"Java\",len([x for x in java if x]))\n",
    "# C = [re.findall(\"[\\s,\\.\\-(\\\\\\]C([\\s,\\.\\-)\\]\\\\\\]|\\+\\+|SHARP)\",i,re.IGNORECASE) for i in desc_col.values]\n",
    "# print(\"C, C++, or Csharp\",len([x for x in C if x]))\n",
    "# hadoop = [re.findall(\"HADOOP\",i,re.IGNORECASE) for i in desc_col.values]\n",
    "# print(\"Hadoop\", len([x for x in hadoop if x]))\n",
    "# spark = [re.findall(\"SPARK\",i,re.IGNORECASE) for i in desc_col.values]\n",
    "# print(\"Spark\", len([x for x in hadoop if x]))\n",
    "# excel = [re.findall(\"Excel[\\s,\\.\\-)\\]\\\\\\)]\", i) for i in desc_col.values]\n",
    "# print(\"Excel\",len([x for x in excel if x]))\n",
    "# sas = [re.findall(\"SAS\", i) for i in desc_col.values]\n",
    "# print(\"SAS\", len([x for x in sas if x]))\n",
    "# stata = [re.findall(\"STATA\", i, re.IGNORECASE) for i in desc_col.values]\n",
    "# print(\"Stata\",len([x for x in stata if x]))\n",
    "# matlab = [re.findall(\"MATLAB\", i, re.IGNORECASE) for i in desc_col.values]\n",
    "# print(\"Matlab\",len([x for x in matlab if x]))\n",
    "# scala = [re.findall(\"SCALA(?![A-Z])\", i, re.IGNORECASE) for i in desc_col.values]\n",
    "# print(\"Scala\",len([x for x in scala if x]))\n",
    "# vba = [re.findall(\"VBA\", i, re.IGNORECASE) for i in desc_col.values]\n",
    "# print(\"VBA\",len([x for x in vba if x]))\n",
    "# tableau = [re.findall(\"TABLEAU\", i, re.IGNORECASE) for i in desc_col.values]\n",
    "# print(\"tableau\",len([x for x in tableau if x]))\n",
    "# h2o = [re.findall(\"H2[O|0]\", i, re.IGNORECASE) for i in desc_col.values]\n",
    "# print(\"h2o\",len([x for x in h2o if x]))\n",
    "# ruby = [re.findall(\"RUBY\", i, re.IGNORECASE) for i in desc_col.values]\n",
    "# print(\"ruby\",len([x for x in ruby if x]))\n",
    "# html = [re.findall(\"HTML\", i, re.IGNORECASE) for i in desc_col.values]\n",
    "# print(\"HTML\",len([x for x in html if x]))\n",
    "# css = [re.findall(\"CSS\", i, re.IGNORECASE) for i in desc_col.values]\n",
    "# print(\"CSS\",len([x for x in css if x]))\n",
    "# javascript = [re.findall(\"JAVA-?\\s?SCRIPT\", i, re.IGNORECASE) for i in desc_col.values]\n",
    "# print(\"javascript\",len([x for x in javascript if x]))\n",
    "# hive = [re.findall(\"(.{20})(?<!ARC)(HIVE)(.{20})\",i,re.IGNORECASE) for i in desc_col.values]\n",
    "# print(\"hive\",len([x for x in hive if x]))\n",
    "webscrape = [re.findall(\"SCRAPY|SELENIUM|SCRAPE|SCRAPING|WEB SCRAP\",i,re.IGNORECASE) for i in desc_col.values]\n",
    "print(\"webscrape\",len([x for x in webscrape if x]))\n",
    "# arcgis\n",
    "# regression\n",
    "# tensorflow\n",
    "# Keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1664\n"
     ]
    }
   ],
   "source": [
    "#Need to change the word numbers into ints\n",
    "desc_col = distinct_df[\"description\"]\n",
    "desc_col = desc_col.reset_index(drop=True)\n",
    "print(len(desc_col))\n",
    "# print(desc_col)\n",
    "# print(type(desc_col))\n",
    "# print(desc_col.values)\n",
    "\n",
    "numbers = dict({\"one\":1, \"two\":2, \"three\":3, \"four\":4,\"five\":5, \"six\":6, \"seven\":7, \"eight\":8, \"nine\":9, \"ten\":10,\n",
    "                \"eleven\":11, \"twelve\":12, \"thirteen\":13, \"fourteen\":14, \"fifteen\":15, \"sixteen\":16, \"seventeen\":17,\n",
    "                \"eighteen\":18, \"nineteen\":19})\n",
    "\n",
    "ans = []\n",
    "def numToInt(column):\n",
    "    for num in numbers.items():\n",
    "        for desc in column:\n",
    "            desc = desc.replace(num[0], str(num[1]))\n",
    "            ans.append(desc)\n",
    "    return(ans)\n",
    "    \n",
    "    \n",
    "#     [num_dic.key]\n",
    "#     for num in numbers.values():\n",
    "#         print\n",
    "\n",
    "temp = numToInt(desc_col)\n",
    "\n",
    "for i in range(0,len(desc_col)-1):\n",
    "    desc_col.values[i] = temp[i]\n",
    "    #want to go into the column, then for every value, if the word is in the dictionary, change it to a number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-21-d9b7ae204803>, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-21-d9b7ae204803>\"\u001b[1;36m, line \u001b[1;32m10\u001b[0m\n\u001b[1;33m    if int(sub_list[0])\u001b[0m\n\u001b[1;37m                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "temp = [re.findall(\"(\\d.{0,5}\\d)(.{0,20})((?<!/)years?)\", i, re.IGNORECASE) for i in desc_col.values]\n",
    "temp\n",
    "# for i in temp:\n",
    "#     if i!=None:\n",
    "#         i = i[0]\n",
    "#go into the list. look at every sublist. if the first element of that sublist is greater than 15, drop it\n",
    "for over_list in temp:\n",
    "    try:\n",
    "        for sub_list in over_list:\n",
    "            if int(sub_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "type": "bar",
         "x": [
          "Billerica, MA",
          "Cambridge, MA",
          "Boston, MA",
          "Waltham, MA",
          "Hanscom AFB, MA",
          "Lexington, MA",
          "Burlington, MA",
          "Woburn, MA",
          "Concord, MA",
          "Somerville, MA",
          "Framingham, MA",
          "Watertown, MA",
          "Bedford, MA",
          "Lowell, MA",
          "Wilmington, MA",
          "Ipswich, MA",
          "Newton Center, MA",
          "Westford, MA",
          "Medford, MA",
          "Quincy, MA",
          "Norwood, MA",
          "Andover, MA",
          "Natick, MA",
          "Danvers, MA",
          "New York, NY",
          "Brooklyn, NY",
          "Jersey City, NJ",
          "Short Hills, NJ",
          "Fort Lee, NJ",
          "Newark, NJ",
          "Yonkers, NY",
          "Ridgefield, NJ",
          "Hoboken, NJ",
          "Livingston, NJ",
          "Rockleigh, NJ",
          "East Hanover, NJ",
          "Orangeburg, NY",
          "Chatham, NJ",
          "Parsippany, NJ",
          "Crystal City, VA",
          "Springfield, VA",
          "Falls Church, VA",
          "Washington, DC",
          "Arlington, VA",
          "Silver Spring, MD",
          "Reston, VA",
          "Rockville, MD",
          "McLean, VA",
          "Tyson's Corner, Fairfax, VA",
          "Alexandria, VA",
          "Upper Marlboro, MD",
          "Bethesda, MD",
          "Fairfax, VA",
          "Annapolis Junction, MD",
          "Gaithersburg, MD",
          "Fort Belvoir, VA",
          "Chantilly, VA",
          "Herndon, VA",
          "Flushing, NY",
          "Iselin, NJ",
          "Fort Meade, MD",
          "Hyattsville, MD",
          "Jessup, MD",
          "Columbia, MD",
          "Chevy Chase, MD",
          "College Park, MD",
          "San Jose, CA",
          "Stanford, CA",
          "Milpitas, CA",
          "Santa Clara, CA",
          "Mountain View, CA",
          "Redwood City, CA",
          "Cupertino, CA",
          "Menlo Park, CA",
          "Sunnyvale, CA",
          "Greenbelt, MD",
          "Mc Lean, VA",
          "Palo Alto, CA",
          "Pleasanton, CA",
          "Livermore, CA",
          "Los Gatos, CA",
          "Fremont, CA",
          "San Carlos, CA",
          "Campbell, CA",
          "Azusa, CA",
          "Pasadena, CA",
          "Venice, CA",
          "Los Angeles, CA",
          "Buena Park, CA",
          "Santa Fe Springs, Los Angeles, CA",
          "Woodland Hills, CA",
          "Long Beach, CA",
          "Burbank, CA",
          "Santa Monica, CA",
          "El Segundo, CA",
          "Sherman Oaks, CA",
          "Glendale, CA",
          "Culver City, CA",
          "Anaheim, CA",
          "Monrovia, CA",
          "Rosemead, CA",
          "Torrance, CA",
          "Irwindale, CA",
          "Hawthorne, CA",
          "Marina del Rey, CA",
          "Monterey Park, CA",
          "Compton, CA",
          "El Monte, CA",
          "Hollywood, CA",
          "Chicago, IL",
          "Itasca, IL",
          "Skokie, IL",
          "Deerfield, IL",
          "Seal Beach, CA",
          "Cypress, CA",
          "Calabasas, CA",
          "Encino, CA",
          "Northridge, CA",
          "Gardena, CA",
          "Cerritos, CA",
          "Playa Vista, CA",
          "Bell, CA",
          "Northbrook, IL",
          "Downers Grove, IL",
          "Oakbrook Terrace, IL",
          "Elmhurst, IL",
          "Burr Ridge, IL",
          "Bolingbrook, IL",
          "Westchester, IL",
          "Hammond, IN",
          "Midlothian, IL",
          "Lisle, IL",
          "Glenview, IL",
          "Lombard, IL",
          "Bridgeview, IL",
          "Addison, IL",
          "Des Plaines, IL",
          "Tinley Park, IL",
          "Austin, TX",
          "Cedar Park, TX",
          "Huntsville, AL",
          "Seattle, WA",
          "Kent, WA",
          "Bothell, WA",
          "Bellevue, WA",
          "Redmond, WA",
          "Renton, WA",
          "Mountlake Terrace, WA",
          "Kirkland, WA",
          "Centennial, CO",
          "Boulder, CO",
          "Broomfield, CO",
          "Golden, CO",
          "Westminster, CO",
          "Lakewood, CO",
          "Greenwood Village, Arapahoe, CO",
          "Denver, CO",
          "Highlands Ranch, CO",
          "Englewood, CO",
          "Tukwila, WA",
          "Auburn, WA",
          "Federal Way, WA",
          "Louisville, CO",
          "Lone Tree, CO",
          "Littleton, CO",
          "San Francisco, CA",
          "San Mateo, CA",
          "South San Francisco, CA",
          "San Ramon, CA",
          "Brisbane, CA",
          "Greenbrae, CA",
          "Mill Valley, CA",
          "Oakland, CA",
          "Burlingame, CA",
          "Emeryville, CA",
          "Berkeley, CA",
          "Crockett, CA",
          "Sausalito, CA",
          "Foster City, CA",
          "Martinez, CA",
          "Alameda, CA",
          "Coral Gables, FL",
          "Miramar, FL",
          "Fort Lauderdale, FL",
          "Miami, FL",
          "Coconut Grove, FL",
          "Hollywood, FL",
          "Miami Lakes, FL",
          "Plantation, FL",
          "South Miami, FL",
          "Tampa, FL",
          "Saint Petersburg, FL",
          "Largo, FL",
          "Clearwater, FL",
          "Pinellas Park, FL",
          "Brandon, FL",
          "Houston, TX",
          "Sugar Land, TX",
          "Webster, TX",
          "Spring, TX",
          "Stafford, TX",
          "Pearland, TX",
          "League City, TX",
          "Atlanta, GA",
          "Smyrna, GA",
          "Stone Mountain, GA",
          "Duluth, GA",
          "Alpharetta, GA",
          "Dunwoody, GA",
          "Norcross, GA",
          "Kennesaw, GA",
          "Roswell, GA",
          "Doraville, GA",
          "Sandy Springs, Fulton, GA",
          "Johns Creek, GA"
         ],
         "y": [
          1,
          1,
          5,
          11,
          5,
          1,
          4,
          21,
          70,
          2,
          18,
          1,
          1,
          1,
          17,
          2,
          7,
          1,
          1,
          74,
          1,
          8,
          1,
          1,
          1,
          3,
          4,
          3,
          8,
          2,
          6,
          1,
          3,
          39,
          1,
          1,
          6,
          1,
          3,
          1,
          1,
          119,
          5,
          1,
          2,
          1,
          1,
          2,
          3,
          1,
          2,
          3,
          3,
          1,
          1,
          1,
          28,
          1,
          1,
          2,
          2,
          1,
          1,
          1,
          9,
          3,
          5,
          3,
          8,
          3,
          1,
          2,
          1,
          4,
          8,
          2,
          1,
          2,
          2,
          5,
          3,
          1,
          3,
          1,
          1,
          1,
          1,
          4,
          1,
          1,
          1,
          3,
          1,
          2,
          2,
          1,
          55,
          14,
          2,
          1,
          1,
          1,
          2,
          2,
          1,
          2,
          2,
          1,
          1,
          2,
          1,
          1,
          6,
          1,
          1,
          1,
          2,
          1,
          1,
          4,
          64,
          1,
          3,
          2,
          1,
          1,
          1,
          4,
          3,
          8,
          1,
          7,
          1,
          1,
          6,
          3,
          2,
          3,
          25,
          1,
          1,
          201,
          2,
          1,
          2,
          5,
          2,
          1,
          3,
          2,
          1,
          28,
          2,
          7,
          1,
          1,
          1,
          1,
          5,
          1,
          10,
          17,
          2,
          8,
          1,
          2,
          8,
          1,
          1,
          9,
          2,
          122,
          40,
          11,
          2,
          2,
          19,
          3,
          16,
          1,
          1,
          64,
          2,
          1,
          4,
          1,
          3,
          1,
          1,
          8,
          1,
          10,
          1,
          3,
          2,
          2,
          17,
          25,
          1,
          1,
          1,
          4,
          1,
          2,
          8,
          85,
          2,
          2,
          1,
          1,
          3,
          1,
          2,
          4,
          1
         ]
        }
       ],
       "layout": {
        "title": "Data Science Job Offerings Based on Location"
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly\n",
    "from plotly.graph_objs import Figure, Histogram, Bar, Layout\n",
    "loc_cat = distinct_df[\"job_location\"].unique()\n",
    "# print(type(loc_cat))\n",
    "loc_count = distinct_df.groupby(\"job_location\")[\"job_location\"].count()\n",
    "# print((loc_count))\n",
    "data = [Bar(x=loc_cat, y = loc_count)]\n",
    "# location_df = distinct_df.groupby(\"job_location\").count()\n",
    "layout = Layout(title=\"Data Science Job Offerings Based on Location\")\n",
    "fig = Figure(data=data, layout=layout)\n",
    "plotly.offline.iplot(fig)\n",
    "\n",
    "# import plotly.plotly as py\n",
    "# import plotly.graph_objs as go\n",
    "\n",
    "# data = [go.Bar(\n",
    "#             x=['giraffes', 'orangutans', 'monkeys'],\n",
    "#             y=[20, 14, 23]\n",
    "#     )]\n",
    "\n",
    "# py.iplot(data, filename='basic-bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'replace'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-114-d0394d120bf9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmedian_rent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"D:/NYC-Data-Science/Projects/Webscrapping-Project/glassdoor/Data/Top 25 DS cities median rent.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtop25_median\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdistinct_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmedian_rent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"inner\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_on\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"job_location\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_on\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Location\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"salary_est\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"$\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"salary_est\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# top25_median[\"Median Yearly 1 BB rent\"]= top25_median[\"Median Yearly 1 BB rent\"].astype(int)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-114-d0394d120bf9>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmedian_rent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"D:/NYC-Data-Science/Projects/Webscrapping-Project/glassdoor/Data/Top 25 DS cities median rent.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtop25_median\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdistinct_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmedian_rent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"inner\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_on\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"job_location\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_on\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Location\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"salary_est\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"$\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"salary_est\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# top25_median[\"Median Yearly 1 BB rent\"]= top25_median[\"Median Yearly 1 BB rent\"].astype(int)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'replace'"
     ]
    }
   ],
   "source": [
    "median_rent = pd.read_csv(\"D:/NYC-Data-Science/Projects/Webscrapping-Project/glassdoor/Data/Top 25 DS cities median rent.csv\")\n",
    "top25_median = distinct_df.merge(median_rent,how = \"inner\", left_on = \"job_location\", right_on = \"Location\", sort = True)\n",
    "df[\"salary_est\"] = [int(i.replace(\"$\",\"\").replace(\",\",\"\")) for i in df[\"salary_est\"]]\n",
    "\n",
    "# top25_median[\"Median Yearly 1 BB rent\"]= top25_median[\"Median Yearly 1 BB rent\"].astype(int)\n",
    "top25_median\n",
    "# top25_median[\"sal_ratio\"] = top25_median[\"salary_est\"]/top25_median[\"Median Yearly 1 BB rent\"]\n",
    "# top25_median[\"sorted_med\"] = top25_median.groupby(\"job_location\")[\"salary_est\"].agg(\"median\")\n",
    "# top25_median = top25_median.sort_values(\"sorted_med\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "['MA' 'NY' 'NJ' 'VA' 'DC' 'MD' 'CA' 'IL' 'IN' 'TX' 'AL' 'WA' 'CO' 'FL' 'GA']\n",
      "CA    506\n",
      "NY    207\n",
      "MA    159\n",
      "IL    147\n",
      "WA    102\n",
      "GA     99\n",
      "DC     85\n",
      "TX     82\n",
      "CO     70\n",
      "VA     69\n",
      "FL     68\n",
      "MD     36\n",
      "NJ     19\n",
      "AL     14\n",
      "IN      1\n",
      "Name: state, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "distinct_df[\"state\"] = distinct_df[\"job_location\"].str[-2:]\n",
    "print(len(distinct_df[\"state\"].unique()))\n",
    "print(distinct_df[\"state\"].unique())\n",
    "\n",
    "print(distinct_df['state'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "type": "bar",
         "x": [
          14,
          506,
          70,
          85,
          68,
          99,
          147,
          1,
          159,
          36,
          19,
          207,
          82,
          69,
          102
         ],
         "y": [
          14,
          506,
          70,
          85,
          68,
          99,
          147,
          1,
          159,
          36,
          19,
          207,
          82,
          69,
          102
         ]
        }
       ],
       "layout": {
        "title": "Data Science Job Offerings Based on Location"
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "distinct_df = distinct_df.sort_values(\"state\")\n",
    "loc_cat = distinct_df[\"state\"].unique()\n",
    "# print(type(loc_cat))\n",
    "loc_count = distinct_df.groupby(\"state\")[\"state\"].count()\n",
    "# print(loc_count)\n",
    "data = [Bar(x=loc_count, y = loc_count)]\n",
    "# location_df = distinct_df.groupby(\"job_location\").count()\n",
    "layout = Layout(title=\"Data Science Job Offerings Based on Location\")\n",
    "fig = Figure(data=data, layout=layout)\n",
    "plotly.offline.iplot(fig, show_link=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Huntsville, AL' 'Mountain View, CA' 'San Francisco, CA' 'San Mateo, CA'\n",
      " 'Redwood City, CA' 'Palo Alto, CA' 'Burlingame, CA' 'Berkeley, CA'\n",
      " 'Emeryville, CA' 'San Jose, CA' 'Los Angeles, CA'\n",
      " 'South San Francisco, CA' 'San Ramon, CA' 'Mill Valley, CA' 'Oakland, CA'\n",
      " 'Greenbrae, CA' 'Crockett, CA' 'Long Beach, CA' 'Sunnyvale, CA'\n",
      " 'Cupertino, CA' 'Santa Clara, CA' 'Milpitas, CA' 'Pleasanton, CA'\n",
      " 'San Carlos, CA' 'Fremont, CA' 'Campbell, CA' 'Santa Monica, CA'\n",
      " 'Pasadena, CA' 'Menlo Park, CA' 'Buena Park, CA' 'Burbank, CA'\n",
      " 'Venice, CA' 'Azusa, CA' 'Woodland Hills, CA'\n",
      " 'Santa Fe Springs, Los Angeles, CA' 'Alameda, CA' 'Foster City, CA'\n",
      " 'Martinez, CA' 'Brisbane, CA' 'Sausalito, CA' 'Stanford, CA'\n",
      " 'El Segundo, CA' 'Seal Beach, CA' 'El Monte, CA' 'Cypress, CA'\n",
      " 'Calabasas, CA' 'Encino, CA' 'Northridge, CA' 'Hollywood, CA'\n",
      " 'Gardena, CA' 'Playa Vista, CA' 'Monrovia, CA' 'Sherman Oaks, CA'\n",
      " 'Anaheim, CA' 'Cerritos, CA' 'Bell, CA' 'Compton, CA' 'Los Gatos, CA'\n",
      " 'Monterey Park, CA' 'Livermore, CA' 'Culver City, CA' 'Glendale, CA'\n",
      " 'Hawthorne, CA' 'Irwindale, CA' 'Rosemead, CA' 'Torrance, CA'\n",
      " 'Marina del Rey, CA' 'Denver, CO' 'Boulder, CO' 'Centennial, CO'\n",
      " 'Littleton, CO' 'Englewood, CO' 'Broomfield, CO'\n",
      " 'Greenwood Village, Arapahoe, CO' 'Golden, CO' 'Westminster, CO'\n",
      " 'Louisville, CO' 'Highlands Ranch, CO' 'Lakewood, CO' 'Lone Tree, CO'\n",
      " 'Washington, DC' 'Miami Lakes, FL' 'Saint Petersburg, FL' 'Miramar, FL'\n",
      " 'Tampa, FL' 'Clearwater, FL' 'Fort Lauderdale, FL' 'Miami, FL' 'Largo, FL'\n",
      " 'Plantation, FL' 'South Miami, FL' 'Coral Gables, FL' 'Brandon, FL'\n",
      " 'Hollywood, FL' 'Coconut Grove, FL' 'Pinellas Park, FL' 'Atlanta, GA'\n",
      " 'Sandy Springs, Fulton, GA' 'Stone Mountain, GA' 'Dunwoody, GA'\n",
      " 'Duluth, GA' 'Alpharetta, GA' 'Smyrna, GA' 'Norcross, GA' 'Roswell, GA'\n",
      " 'Doraville, GA' 'Kennesaw, GA' 'Johns Creek, GA' 'Chicago, IL'\n",
      " 'Skokie, IL' 'Itasca, IL' 'Northbrook, IL' 'Oakbrook Terrace, IL'\n",
      " 'Tinley Park, IL' 'Des Plaines, IL' 'Elmhurst, IL' 'Bridgeview, IL'\n",
      " 'Downers Grove, IL' 'Lisle, IL' 'Burr Ridge, IL' 'Deerfield, IL'\n",
      " 'Glenview, IL' 'Midlothian, IL' 'Westchester, IL' 'Bolingbrook, IL'\n",
      " 'Addison, IL' 'Lombard, IL' 'Hammond, IN' 'Boston, MA' 'Wilmington, MA'\n",
      " 'Waltham, MA' 'Cambridge, MA' 'Hanscom AFB, MA' 'Watertown, MA'\n",
      " 'Woburn, MA' 'Burlington, MA' 'Bedford, MA' 'Norwood, MA' 'Lexington, MA'\n",
      " 'Lowell, MA' 'Concord, MA' 'Framingham, MA' 'Somerville, MA' 'Quincy, MA'\n",
      " 'Westford, MA' 'Danvers, MA' 'Medford, MA' 'Billerica, MA' 'Natick, MA'\n",
      " 'Ipswich, MA' 'Andover, MA' 'Newton Center, MA' 'Bethesda, MD'\n",
      " 'Rockville, MD' 'Silver Spring, MD' 'Columbia, MD' 'Jessup, MD'\n",
      " 'Annapolis Junction, MD' 'Hyattsville, MD' 'Gaithersburg, MD'\n",
      " 'Fort Meade, MD' 'Upper Marlboro, MD' 'Greenbelt, MD' 'College Park, MD'\n",
      " 'Chevy Chase, MD' 'Newark, NJ' 'Short Hills, NJ' 'Parsippany, NJ'\n",
      " 'Fort Lee, NJ' 'Jersey City, NJ' 'Iselin, NJ' 'East Hanover, NJ'\n",
      " 'Chatham, NJ' 'Livingston, NJ' 'Ridgefield, NJ' 'Hoboken, NJ'\n",
      " 'Rockleigh, NJ' 'New York, NY' 'Flushing, NY' 'Orangeburg, NY'\n",
      " 'Yonkers, NY' 'Brooklyn, NY' 'Houston, TX' 'Austin, TX' 'Sugar Land, TX'\n",
      " 'Cedar Park, TX' 'Pearland, TX' 'League City, TX' 'Webster, TX'\n",
      " 'Spring, TX' 'Stafford, TX' 'Alexandria, VA' \"Tyson's Corner, Fairfax, VA\"\n",
      " 'Arlington, VA' 'Herndon, VA' 'McLean, VA' 'Reston, VA' 'Fort Belvoir, VA'\n",
      " 'Springfield, VA' 'Crystal City, VA' 'Chantilly, VA' 'Fairfax, VA'\n",
      " 'Falls Church, VA' 'Mc Lean, VA' 'Seattle, WA' 'Renton, WA' 'Bellevue, WA'\n",
      " 'Redmond, WA' 'Kirkland, WA' 'Bothell, WA' 'Kent, WA' 'Tukwila, WA'\n",
      " 'Auburn, WA' 'Federal Way, WA' 'Mountlake Terrace, WA']\n"
     ]
    }
   ],
   "source": [
    "print(distinct_df[\"job_location\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"HOW TO GET CITY INFORMATION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "distinct_df.sort_values(Size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cities = [\"boston\",\"new-york\",\"washington\",\"san-jose\",\"los-angeles\",\"chicago\",\"austin\",\"huntsville\",\"seattle\",\"denver\",\"san-francisco\",\"miami\",\"tampa\",\"palo-alto\",\"houston\",\"atlanta\"]\n",
    "city_ids = [1154532,1132348,1138213,1147436,1146821,1128808,1139761,1127653,1150505,1148170,1147401,1154170,1154429,1147434,1140171,1155583 ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    for city_id in city_ids:\n",
    "        for i in range(1,31):\n",
    "            pass\n",
    "#             print(\"https://www.glassdoor.com/Job/new-york-data-scientist-jobs-SRCH_IL.0,8_IC\"+\n",
    "#                   str(city_id)+\n",
    "#                   \"_KO9,23_IP\"+\n",
    "#                   str(i)+\n",
    "#                   \".htm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x =[(\"https://www.glassdoor.com/Job/new-york-data-scientist-jobs-SRCH_IL.0,8_IC\" + \n",
    "    str(city_id) +\n",
    "    \"_KO9,23_IP\" +\n",
    "    str(num) + \n",
    "    \".htm\") for city_id in city_ids for num in range(1,31)]\n",
    "# x\n",
    "#[x for y in collection for x in y] # [A for B in C for D in E]\n",
    "#for y in collection:     #      for B in C:\n",
    "#    for x in y:          #          for D in E: (in this case: for A in B)\n",
    "        # receive x      #              # receive A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# [str(len(city)) for city in cities]\n",
    "# [str(len(city)+14) for city in cities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cities = list(zip(cities,city_ids))\n",
    "cities #this has the right line up\n",
    "start_url = [(\"https://www.glassdoor.com/Job/\"+\n",
    "              # city name\n",
    "              city[0]+\n",
    "              # the job position we are looking for with some standard text. Start the search for the location at 0\n",
    "              \"-data-scientist-jobs-SRCH_IL.0,\"+\n",
    "              # and the last character for the city is the city length (including hyphens)\n",
    "              str(len(city[0]))+\n",
    "              # location code\n",
    "              \"_IC\"+\n",
    "              str(city[1])+\n",
    "              \"_KO\"+\n",
    "              # looking up the occupation search term which is 1 after the city length (doesn't include hyphen)\n",
    "              str(len(city[0])+1)+\n",
    "              \",\"+\n",
    "              #and the job term ends 15 characters after \"-data-scientist\"\n",
    "              str(len(city[0])+15)+\n",
    "              \"_IP\"+\n",
    "              #the page number we are looking for\n",
    "              str(i) +\n",
    "              #only pages 1 to 30 since pages 31+ don't exist on the website\n",
    "              \".htm\") for city in cities for i in range(1,31)]\n",
    "start_url\n",
    "\n",
    "cities[1][0]\n",
    "\n",
    "#PROPER SAN JOSE: https://www.glassdoor.com/Job/san-jose-data-scientist-jobs-SRCH_IL.0,8_IC1147436_KO9,23_IP2.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = [url + \"_KO9,23_IP\" for url in x]\n",
    "# x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = (range(1,31))\n",
    "# [(url + str(num) + \".htm\") for url in x for num in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " seq_x = [1, 2, 3, 4]\n",
    "seq_y = 'abc'\n",
    "[(x,y) for x in seq_x for y in seq_y]\n",
    "[(1, 'a'), \n",
    " (1, 'b'), \n",
    " (1, 'c'), \n",
    " (2, 'a'), \n",
    " (2, 'b'), \n",
    " (2, 'c'), \n",
    " (3, 'a'), \n",
    " (3, 'b'), \n",
    " (3, 'c'), \n",
    " (4, 'a'), \n",
    " (4, 'b'), \n",
    " (4, 'c')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[\"https://www.glassdoor.com/Job/new-york-data-scientist-jobs-SRCH_IL.0,8_IC\"+str(city_id)+\"_KO9,23_IP\"+str(i)+\".htm\" for city_id for i in range(1,31) for city_id in city_ids]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not all(item.values()):\n",
    "\traise DropItem(\"Missing values!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
